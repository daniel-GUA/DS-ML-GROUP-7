{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fac4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer #Package for the vader method of sentiment analysis\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator #Package for wordcloud to see most occcuring words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcd93de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#READ the dataset\n",
    "data = pd.read_csv(\"omicron1.csv\")\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a66f3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"hashtags\"].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d83f107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see = []\n",
    "# str(hash1) for hash1 in set(data[\"hashtags\"]):\n",
    "#     if hash1 == :\n",
    "#         see.append(hash1)\n",
    "#     see.extend(hash1)\n",
    "# print(see.head(7))\n",
    "# def clean(hashtag):\n",
    "#     hashtag = re.sub('','None', hashtag)\n",
    "#     text = str(text).lower()\n",
    "#     text = re.sub('\\[.*?\\]', '', text)\n",
    "#     text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "#     text = re.sub('<.*?>+', '', text)\n",
    "#     text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "#     text = re.sub('\\n', '', text)\n",
    "#     text = re.sub('\\w*\\d\\w*', '', text)\n",
    "#     text = [word for word in text.split(' ') if word not in stopword]\n",
    "#     text=\" \".join(text)\n",
    "#     text = [stemmer.stem(word) for word in text.split(' ')]\n",
    "#     text=\" \".join(text)\n",
    "#     return hashtag\n",
    "# data22 = data[\"hashtags_filled\"].apply(clean)\n",
    "# print(data[\"hashtags_filled\"].head(3))\n",
    "# print(data[\"hashtags\"].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d0089c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"hashtags_filled\"]= data[\"hashtags\"].fillna('None') # Fill NaN with None\n",
    "#Clean HASHTAGS to get new values that will be useful for chart\n",
    "def Convert(hashtag1):\n",
    "    hashtag1 = re.sub('[\\[\\]\\.*?<.*?>+\\'\\,]','',hashtag1)\n",
    "    split_hashtag1= hashtag1.split(\" \")\n",
    "    return split_hashtag1\n",
    "data[\"hashtags_new\"] = data[\"hashtags_filled\"].apply(Convert)\n",
    "data[\"hashtags_new\"].loc[10:20]\n",
    "# words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3167b1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleans the words in the hashtag and put in a set, so that we can reference it.\n",
    "\n",
    "words_list = []\n",
    "rough = []\n",
    "def Converted():\n",
    "    for hashtag in data[\"hashtags_new\"]:\n",
    "        if isinstance(hashtag, list):\n",
    "            for words in hashtag:\n",
    "                words_list.append(words)\n",
    "#                 for letters in words:\n",
    "        else:\n",
    "            words_list.append(hashtag)\n",
    "    return words_list\n",
    "Converted()\n",
    "set_list = set(words_list)\n",
    "len(set_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d0ed79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sorted_hashtag():\n",
    "    if isinstance(hashtag1, list):\n",
    "        if hashtag1 is in set_list:\n",
    "            hashtag1 =  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26af7831",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check data for missing values\n",
    "data.isna().sum()\n",
    "# from the summary; user_loaction, user_description, hashtags all have missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4669b26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nen1= data[\"hashtags\"].values.tolist()\n",
    "# nen2 = \" \".join(i for i in data.hashtags.apply(str))\n",
    "# print(nen2)\n",
    "# print(\" \")\n",
    "# data[\"hashtags\"].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4629d360",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47958e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stopword=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d515528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = [word for word in text.split(' ') if word not in stopword]\n",
    "    text=\" \".join(text)\n",
    "    text = [stemmer.stem(word) for word in text.split(' ')]\n",
    "    text=\" \".join(text)\n",
    "    return text\n",
    "data[\"text\"] = data[\"text\"].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f84273",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f08634",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(i for i in data.text)\n",
    "stopwords = set(STOPWORDS)\n",
    "wordcloud = WordCloud(stopwords=stopwords, background_color=\"blue\").generate(text)\n",
    "plt.figure( figsize=(15,10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683a12d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "sentiments = SentimentIntensityAnalyzer()\n",
    "data[\"Positive\"] = [sentiments.polarity_scores(i)[\"pos\"] for i in data[\"text\"]]\n",
    "data[\"Negative\"] = [sentiments.polarity_scores(i)[\"neg\"] for i in data[\"text\"]]\n",
    "data[\"Neutral\"] = [sentiments.polarity_scores(i)[\"neu\"] for i in data[\"text\"]]\n",
    "data1 = data[[\"text\", \"Positive\", \"Negative\", \"Neutral\"]]\n",
    "print(data1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d731128",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sum(data[\"Positive\"])\n",
    "y = sum(data[\"Negative\"])\n",
    "z = sum(data[\"Neutral\"])\n",
    "\n",
    "def sentiment_score(a, b, c):\n",
    "    if (a>b) and (a>c):\n",
    "        print(\"Positive ðŸ˜Š \")\n",
    "    elif (b>a) and (b>c):\n",
    "        print(\"Negative ðŸ˜  \")\n",
    "    else:\n",
    "        print(\"Neutral ðŸ™‚ \")\n",
    "sentiment_score(x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8338245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = data[[\"Positive\",\"Negative\",\"Neutral\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6731db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check = [\"Positive\", \"Negative\", \"Neutral\"]\n",
    "# new1= data.groupby(\"text\")[check].mean()\n",
    "# new1.plot(kind = \"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e02fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #data[[\"Positive\",\"Negative\"]].plot(kind = \"scatter\")\n",
    "# plt.plot(data[\"Positive\"], data[\"Neutral\"], 'b')\n",
    "# plt.plot(data[\"Positive\"], data[\"Neutral\"], 'r')\n",
    "# plt.ylabel(\"Negative Neutral\")\n",
    "# plt.xlabel(\"Positive\")\n",
    "# plt.legend([\"Negative\", 'Neutral'])\n",
    "# plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d898d950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5762a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9249311",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
